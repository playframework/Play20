#!/usr/bin/env bash

# Copyright (C) 2009-2019 Lightbend Inc. <https://www.lightbend.com>

# Lib for CI scripts

set -e
set -o pipefail

DIR=$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )
BASEDIR=$DIR/..
export DOCUMENTATION=$BASEDIR/documentation

export CURRENT_BRANCH=${TRAVIS_BRANCH}

AKKA_VERSION=""
AKKA_HTTP_VERSION=""

# Check if it is a scheduled build
if [ "$TRAVIS_EVENT_TYPE" = "cron" ]; then
    # `sort` is not necessary, but it is good to make it predictable.
    AKKA_VERSION=$(curl -s https://repo.akka.io/snapshots/com/typesafe/akka/akka-actor_2.13/ | grep -oEi '2\.6-[0-9]{8}-[0-9]{6}' | sort | tail -n 1)
    AKKA_HTTP_VERSION=$(curl -s https://dl.bintray.com/akka/snapshots/com/typesafe/akka/akka-http-core_2.13/maven-metadata.xml | xmllint --xpath '//latest/text()' -)

    echo "Using Akka SNAPSHOT ${AKKA_VERSION} and Akka HTTP SNAPSHOT ${AKKA_HTTP_VERSION}"

    AKKA_VERSION_OPTS="-Dakka.version=${AKKA_VERSION}"
    AKKA_HTTP_VERSION_OPTS="-Dakka.http.version=${AKKA_HTTP_VERSION}"
fi

printMessage() {
  echo "[info]"
  echo "[info] ---- $1"
  echo "[info]"
}

runSbt() {
  sbt "$AKKA_VERSION_OPTS" "$AKKA_HTTP_VERSION_OPTS" -jvm-opts "$BASEDIR/.travis-jvmopts" 'set concurrentRestrictions in Global += Tags.limitAll(1)' "$@" | grep --line-buffered -v 'Resolving \|Generating '
}

# Runs code formating validation in the current directory
scalafmtValidation() {
  printMessage "VALIDATE SCALA CODE FORMATTING"
  runSbt scalafmtCheckAll scalafmtSbtCheck || (
    echo "[error] ERROR: Scalafmt test failed for $1 source."
    echo "[error] To fix, format your sources using 'sbt scalafmtAll scalafmtSbt' before submitting a pull request."
    false
  )
}

# Runs code formating validation in the current directory
javafmtValidation() {
  printMessage "VALIDATE JAVA CODE FORMATTING"
  runSbt javafmt test:javafmt
  git diff --exit-code || (
    echo "[error] ERROR: javafmt check failed for $1 source, see differences above."
    echo "[error] To fix, format your sources using 'sbt javafmt test:javafmt' before submitting a pull request."
    false
  )
}


startThreadDumpCollector() {
  thread_dump_dir=${HOME}/thread-dumps

  # Give other scripts a chance to start sbt
  sleep 10 # seconds

  printMessage "STARTING THREAD DUMP COLLECTOR"
  mkdir -p "$thread_dump_dir"

  # Some scripts start sbt more than once, so we can
  # retry to get the process a number of times before
  # giving up.
  max_retries=5
  while :
  do
    # Generate a new one so that we can see how things are progressing
    thread_dump_file=${thread_dump_dir}/$(date '+%Y%m%d-%H%M%S').txt
    # Get process id for sbt-launcher
    process_id=$(jps | grep "sbt-launch" | head -n1 | cut -d' ' -f1)

    if [ -z "$process_id" ]; then
      # No sbt process found, so we can stop collecting thread dumps
      printMessage "NO MORE sbt PROCESS. EXITING"
      ((max_retries--))
      if [ "$max_retries" -eq "0" ]; then
        break
      else
        printMessage "WILL RETRY TO READ sbt PROCESS FOR $max_retries TIMES"
        sleep 10 # seconds
      fi
    else
      # There is still a process running, let's keep collecting the thread dumps

      # jstack flags:
      # -l  long listing. Prints additional information about locks
      jstack -l "$process_id" > "$thread_dump_file"
      sleep 60 # seconds
    fi
  done

  # To make it easier to associate the thread dumps with a build/job
  generateBuildMetadata "${thread_dump_dir}"/metadata.txt

  # Create gz file with all thread dumps
  tar -zcvf "${thread_dump_dir}/build.tar.gz" "${thread_dump_dir}"
}

generateBuildMetadata() {
  cat <<EOT >> "${1}"
TRAVIS_BUILD_ID: ${TRAVIS_BUILD_ID}
TRAVIS_BUILD_NUMBER: ${TRAVIS_BUILD_NUMBER}
TRAVIS_BUILD_WEB_URL: ${TRAVIS_BUILD_WEB_URL}

TRAVIS_JOB_ID: ${TRAVIS_JOB_ID}
TRAVIS_JOB_NAME: ${TRAVIS_JOB_NAME}
TRAVIS_JOB_NUMBER: ${TRAVIS_JOB_NUMBER}
TRAVIS_JOB_WEB_URL: ${TRAVIS_JOB_WEB_URL}
EOT
}

# It is not possible to upload artifacts for pull requests:
# https://docs.travis-ci.com/user/uploading-artifacts/
if [ "$TRAVIS_EVENT_TYPE" != "pull_request" ] && [ "$TRAVIS" = "true" ]; then
  # Start when the script is loaded. It is okay to do it here
  # since it is loaded only once for each job.
  startThreadDumpCollector &
fi
